{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Laboratorio: CSV vs Parquet, Micro-batches y KPIs\n",
        "\n",
        "Este cuaderno genera **datasets sintéticos** para tres casos (e-commerce, sensores IoT y logs de fraude), compara **CSV vs Parquet** (tamaño en disco y lectura simple), simula **micro-batches de 60 min** y construye **KPIs sencillos** con visualización en **matplotlib**.\n",
        "\n",
        "**Contenido**:\n",
        "1) Generación de datos sintéticos (3 casos)  \n",
        "2) Comparativa CSV vs Parquet (tamaños)  \n",
        "3) Simulación de micro-batches de 60 min  \n",
        "4) KPIs básicos y gráficos  \n",
        "5) Actividad flash para el equipo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dependencias (mantener aquí para Colab)\n",
        "%pip -q install pyarrow pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "BASE = Path(\"/content\")  # Colab\n",
        "BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def human_size(num_bytes: int) -> str:\n",
        "    if num_bytes == 0:\n",
        "        return \"0 B\"\n",
        "    units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]\n",
        "    power = min(int(math.log(num_bytes, 1024)), len(units)-1)\n",
        "    return f\"{num_bytes / (1024 ** power):.2f} {units[power]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Generación de datasets sintéticos\n",
        "Se crean tres datasets con una ventana temporal de **2 días** con granularidad de minutos.\n",
        "\n",
        "- **E-commerce**: pedidos (order_id, ts, customer_id, sku, qty, price, amount).  \n",
        "- **IoT**: métricas de sensores (sensor_id, ts, temperature, humidity, status).  \n",
        "- **Fraude**: eventos de transacciones (event_id, ts, user_id, ip, amount, is_flagged)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la simulación\n",
        "start = pd.Timestamp(\"2024-06-01 00:00:00\")\n",
        "end   = pd.Timestamp(\"2024-06-03 00:00:00\")\n",
        "ts_index = pd.date_range(start, end, freq=\"1min\", inclusive=\"left\")  # 2 días * 24h * 60\n",
        "\n",
        "# --- E-COMMERCE ---\n",
        "N_orders = 25000\n",
        "ecom = pd.DataFrame({\n",
        "    \"order_id\": np.arange(1, N_orders+1),\n",
        "    \"ts\": np.random.choice(ts_index, size=N_orders, replace=True),\n",
        "    \"customer_id\": np.random.randint(1000, 1999, size=N_orders),\n",
        "    \"sku\": np.random.choice([f\"SKU-{i:04d}\" for i in range(500)], size=N_orders),\n",
        "    \"qty\": np.random.randint(1, 5, size=N_orders),\n",
        "    \"price\": np.round(np.random.uniform(5, 150, size=N_orders), 2),\n",
        "})\n",
        "ecom[\"amount\"] = np.round(ecom[\"qty\"] * ecom[\"price\"], 2)\n",
        "\n",
        "# --- IOT ---\n",
        "N_sensors = 200\n",
        "N_iot = 40000\n",
        "iot = pd.DataFrame({\n",
        "    \"sensor_id\": np.random.choice([f\"S{i:03d}\" for i in range(N_sensors)], size=N_iot),\n",
        "    \"ts\": np.random.choice(ts_index, size=N_iot, replace=True),\n",
        "    \"temperature\": np.round(np.random.normal(24, 3, size=N_iot), 2),\n",
        "    \"humidity\": np.round(np.random.normal(55, 10, size=N_iot), 2),\n",
        "})\n",
        "iot[\"status\"] = np.where((iot[\"temperature\"]>30) | (iot[\"humidity\"]>75), \"alert\", \"ok\")\n",
        "\n",
        "# --- FRAUDE ---\n",
        "N_events = 30000\n",
        "fraud = pd.DataFrame({\n",
        "    \"event_id\": np.arange(1, N_events+1),\n",
        "    \"ts\": np.random.choice(ts_index, size=N_events, replace=True),\n",
        "    \"user_id\": np.random.randint(5000, 7000, size=N_events),\n",
        "    \"ip\": [f\"192.168.{a}.{b}\" for a,b in zip(np.random.randint(0,255,N_events), np.random.randint(1,255,N_events))],\n",
        "    \"amount\": np.round(np.random.exponential(80, size=N_events), 2),\n",
        "})\n",
        "fraud[\"is_flagged\"] = (np.random.rand(N_events) < 0.03) | (fraud[\"amount\"] > 300)\n",
        "\n",
        "ecom.sort_values(\"ts\", inplace=True)\n",
        "iot.sort_values(\"ts\", inplace=True)\n",
        "fraud.sort_values(\"ts\", inplace=True)\n",
        "\n",
        "ecom.head(), iot.head(), fraud.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) CSV vs Parquet (tamaño y lectura simple)\n",
        "Guardamos cada dataset en **CSV** y **Parquet** y medimos **tamaño en disco** y un tiempo simple de lectura (orientativo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "paths = {\n",
        "    \"ecom_csv\": BASE/\"ecommerce.csv\",\n",
        "    \"ecom_parq\": BASE/\"ecommerce.parquet\",\n",
        "    \"iot_csv\": BASE/\"iot.csv\",\n",
        "    \"iot_parq\": BASE/\"iot.parquet\",\n",
        "    \"fraud_csv\": BASE/\"fraud.csv\",\n",
        "    \"fraud_parq\": BASE/\"fraud.parquet\",\n",
        "}\n",
        "\n",
        "# Guardar\n",
        "ecom.to_csv(paths[\"ecom_csv\"], index=False)\n",
        "ecom.to_parquet(paths[\"ecom_parq\"], index=False)\n",
        "iot.to_csv(paths[\"iot_csv\"], index=False)\n",
        "iot.to_parquet(paths[\"iot_parq\"], index=False)\n",
        "fraud.to_csv(paths[\"fraud_csv\"], index=False)\n",
        "fraud.to_parquet(paths[\"fraud_parq\"], index=False)\n",
        "\n",
        "# Tamaños\n",
        "sizes = []\n",
        "for key, p in paths.items():\n",
        "    sizes.append({\"dataset\": key, \"bytes\": os.path.getsize(p), \"human\": human_size(os.path.getsize(p))})\n",
        "sizes_df = pd.DataFrame(sizes).sort_values(\"dataset\")\n",
        "sizes_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lectura: medición simple (no exhaustiva)\n",
        "bench = []\n",
        "\n",
        "for name, p in [(\"ecom_csv\", paths[\"ecom_csv\"]), (\"ecom_parq\", paths[\"ecom_parq\"]),\n",
        "                (\"iot_csv\", paths[\"iot_csv\"]),   (\"iot_parq\", paths[\"iot_parq\"]),\n",
        "                (\"fraud_csv\", paths[\"fraud_csv\"]),(\"fraud_parq\", paths[\"fraud_parq\"])]:\n",
        "    t0 = time.perf_counter()\n",
        "    if name.endswith(\"csv\"):\n",
        "        _ = pd.read_csv(p)\n",
        "    else:\n",
        "        _ = pd.read_parquet(p)\n",
        "    ms = (time.perf_counter() - t0) * 1000\n",
        "    bench.append({\"dataset\": name, \"read_ms\": round(ms, 2)})\n",
        "\n",
        "bench_df = pd.DataFrame(bench)\n",
        "bench_df.sort_values(\"dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Simulación de micro-batches (60 min)\n",
        "Agrupamos por **hora** y contamos cuántos lotes se producirían por dataset (número de horas cubiertas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_hourly_batches(df: pd.DataFrame, ts_col: str) -> int:\n",
        "    hourly = pd.to_datetime(df[ts_col]).dt.floor(\"H\")\n",
        "    return hourly.nunique()\n",
        "\n",
        "batches = pd.DataFrame({\n",
        "    \"dataset\": [\"ecommerce\", \"iot\", \"fraud\"],\n",
        "    \"hourly_batches\": [\n",
        "        count_hourly_batches(ecom, \"ts\"),\n",
        "        count_hourly_batches(iot, \"ts\"),\n",
        "        count_hourly_batches(fraud, \"ts\"),\n",
        "    ]\n",
        "})\n",
        "batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) KPIs y gráficos (matplotlib)\n",
        "Se calculan **tres KPIs sencillos** por hora y se grafican en plots separados:\n",
        "- **E-commerce**: *revenue* por hora (suma de `amount`)  \n",
        "- **IoT**: temperatura media por hora  \n",
        "- **Fraude**: conteo de eventos *flagged* por hora  \n",
        "\n",
        "> Nota: se usa `matplotlib` sin estilos personalizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- E-commerce: revenue por hora ---\n",
        "ecom_hour = (\n",
        "    ecom.assign(hour=pd.to_datetime(ecom[\"ts\"]).dt.floor(\"H\"))\n",
        "        .groupby(\"hour\", as_index=False)[\"amount\"].sum()\n",
        "        .rename(columns={\"amount\":\"revenue\"})\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ecom_hour[\"hour\"], ecom_hour[\"revenue\"])\n",
        "plt.title(\"E-commerce: Revenue por hora\")\n",
        "plt.xlabel(\"Hora\")\n",
        "plt.ylabel(\"Revenue\")\n",
        "plt.xticks(rotation=25)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- IoT: temperatura media por hora ---\n",
        "iot_hour = (\n",
        "    iot.assign(hour=pd.to_datetime(iot[\"ts\"]).dt.floor(\"H\"))\n",
        "       .groupby(\"hour\", as_index=False)[\"temperature\"].mean()\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(iot_hour[\"hour\"], iot_hour[\"temperature\"])\n",
        "plt.title(\"IoT: Temperatura media por hora\")\n",
        "plt.xlabel(\"Hora\")\n",
        "plt.ylabel(\"Temperatura (°C)\")\n",
        "plt.xticks(rotation=25)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Fraude: eventos flagged por hora ---\n",
        "fraud_hour = (\n",
        "    fraud.assign(hour=pd.to_datetime(fraud[\"ts\"]).dt.floor(\"H\"))\n",
        "         .groupby(\"hour\", as_index=False)[\"is_flagged\"].sum()\n",
        "         .rename(columns={\"is_flagged\":\"flagged_count\"})\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fraud_hour[\"hour\"], fraud_hour[\"flagged_count\"])\n",
        "plt.title(\"Fraude: eventos flagged por hora\")\n",
        "plt.xlabel(\"Hora\")\n",
        "plt.ylabel(\"Flagged count\")\n",
        "plt.xticks(rotation=25)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "ecom_hour.head(), iot_hour.head(), fraud_hour.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Actividad flash (completar por el equipo)\n",
        "\n",
        "Rellenar aquí (3–5 minutos):\n",
        "\n",
        "- **Caso elegido**: ☐ *e-commerce* ☐ *IoT* ☐ *fraude*  \n",
        "- **V dominante hoy** y **V dominante si 2× tráfico** (3 líneas):  \n",
        "  1) …  2) …  3) …  \n",
        "- **1 decisión por capa** (Bronze/Silver/Gold):  \n",
        "  - Bronze (ingesta, formato, particionado): …  \n",
        "  - Silver (normalización, reglas): …  \n",
        "  - Gold (KPI, ventana, SLA): …\n",
        "\n",
        "> Opcional: añade conclusiones sobre CSV vs Parquet con los tamaños y tiempos observados."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
